{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=sio.loadmat('ERA_grid.mat')\n",
    "lat=file['lat']\n",
    "lon=file['lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList_test=[]\n",
    "fileList_test.append('geopotential_500hPa_2018_5.625deg.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=nc.Dataset('ERA_Z500_1hour.nc')\n",
    "Z500=np.asarray(file['input'])\n",
    "M=np.mean(Z500.flatten())\n",
    "sdev=np.std(Z500.flatten())\n",
    "noise=0.5\n",
    "from matplotlib import pyplot as plt\n",
    "F=nc.Dataset(fileList_test[0])\n",
    "Z=np.asarray(F['z'])\n",
    "TRUTH=Z\n",
    "[qx,qy]=np.meshgrid(lon,lat)\n",
    "\n",
    "Z_rs = np.reshape(Z,[np.size(Z,0), int(np.size(Z,1)*np.size(Z,2))])\n",
    "TRUTH = Z_rs\n",
    "Z_rs = (Z_rs-M)/sdev\n",
    "TRUTH = (TRUTH-M)/sdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,np.size(Z_rs,0)):\n",
    " Z_rs[k-1,:]=Z_rs[k-1,:]+np.random.normal(0, noise, 2048)\n",
    " \n",
    "print('length of initial condition',len(Z_rs[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENKF(x, n, P ,Q, R, obs, model, u_ensemble):\n",
    "    obs=np.reshape(obs,[n,1]) \n",
    "    x=np.reshape(x,[n,1])\n",
    "    [U,S,V]=np.linalg.svd(P)\n",
    "    D=np.zeros([n,n])\n",
    "    np.fill_diagonal(D,S)\n",
    "    sqrtP=np.dot(np.dot(U,np.sqrt(D)),U)\n",
    "    ens=np.zeros([n,2*n])\n",
    "    ens[:,0:n]=np.tile(x,(1,n)) + sqrtP\n",
    "    ens[:,n:]=np.tile(x,(1,n)) - sqrtP\n",
    "    ## forecasting step,dummy model\n",
    "\n",
    "    for k in range(0, np.size(ens,1)):\n",
    "\n",
    "       u =  model.predict(np.reshape(ens[:,k],[1, 32, 64, 1]))\n",
    "\n",
    "       u_ensemble[:,k]=np.reshape(u,(32*64,))\n",
    "\n",
    "\n",
    "    ############################\n",
    "    x_prior = np.reshape(np.mean(u_ensemble,1),[n,1])\n",
    "    print('shape pf x_prior',np.shape(x_prior))\n",
    "    print('shape pf obs',np.shape(obs))\n",
    "    cf_ens = ens - np.tile(x_prior,(1,2*n))\n",
    "    P_prior = np.dot(cf_ens,np.transpose(cf_ens))/(2*n - 1)+Q\n",
    "    h_ens = ens\n",
    "    y_prior=np.reshape(np.mean(h_ens,1),[n,1])\n",
    "    ch_ens = h_ens - np.tile(y_prior,(1,2*n))\n",
    "    print('shape pf y_prior',np.shape(y_prior))\n",
    "    P_y = np.dot(ch_ens, np.transpose(ch_ens))/(2*n-1) + R\n",
    "    P_xy = np.dot(cf_ens, np.transpose(ch_ens)) /(2*n-1)\n",
    "    K = np.dot(P_xy,np.linalg.inv(P_y))\n",
    "    P = P_prior - np.dot(np.dot(K,P_y),np.transpose(K))\n",
    "    x = x_prior + np.dot(K,(obs-y_prior))\n",
    "\n",
    "    return x, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras.backend as K\n",
    "#from data_manager import ClutteredMNIST\n",
    "#from visualizer import plot_mnist_sample\n",
    "#from visualizer import print_evaluation\n",
    "#from visualizer import plot_mnist_grid\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "from keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
    "                          Flatten, concatenate, Activation, Reshape, \\\n",
    "                          UpSampling2D,ZeroPadding2D\n",
    "import keras\n",
    "from keras.callbacks import History\n",
    "history = History()\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Cropping2D, Concatenate, ZeroPadding2D\n",
    "from keras.models import load_model\n",
    "\n",
    "__version__ = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CConv2D(filters, kernel_size, strides=(1, 1), activation='linear', padding='valid', kernel_initializer='glorot_uniform', kernel_regularizer=None):\n",
    "    def CConv2D_inner(x):\n",
    "        # padding (see https://www.tensorflow.org/api_guides/python/nn#Convolution)\n",
    "        in_height = int(x.get_shape()[1])\n",
    "        in_width = int(x.get_shape()[2])\n",
    "\n",
    "        if (in_height % strides[0] == 0):\n",
    "            pad_along_height = max(kernel_size[0] - strides[0], 0)\n",
    "        else:\n",
    "            pad_along_height = max(\n",
    "                kernel_size[0] - (in_height % strides[0]), 0)\n",
    "        if (in_width % strides[1] == 0):\n",
    "            pad_along_width = max(kernel_size[1] - strides[1], 0)\n",
    "        else:\n",
    "            pad_along_width = max(kernel_size[1] - (in_width % strides[1]), 0)\n",
    "\n",
    "        pad_top = pad_along_height // 2\n",
    "        pad_bottom = pad_along_height - pad_top\n",
    "        pad_left = pad_along_width // 2\n",
    "        pad_right = pad_along_width - pad_left\n",
    "\n",
    "        # left and right side for padding\n",
    "        pad_left = Cropping2D(cropping=((0, 0), (in_width-pad_left, 0)))(x)\n",
    "        pad_right = Cropping2D(cropping=((0, 0), (0, in_width-pad_right)))(x)\n",
    "\n",
    "        # add padding to incoming image\n",
    "        conc = Concatenate(axis=2)([pad_left, x, pad_right])\n",
    "\n",
    "        # top/bottom padding options\n",
    "        if padding == 'same':\n",
    "            conc = ZeroPadding2D(padding={'top_pad': pad_top,\n",
    "                                          'bottom_pad': pad_bottom})(conc)\n",
    "        elif padding == 'valid':\n",
    "            pass\n",
    "        else:\n",
    "            raise Exception('Padding \"{}\" does not exist!'.format(padding))\n",
    "\n",
    "        # perform the circular convolution\n",
    "        cconv2d = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                         strides=strides, activation=activation,\n",
    "                         padding='valid',\n",
    "                         kernel_initializer=kernel_initializer,\n",
    "                         kernel_regularizer=kernel_regularizer)(conc)\n",
    "\n",
    "        # return circular convolution layer\n",
    "        return cconv2d\n",
    "    return CConv2D_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "\n",
    "from utils import get_initial_weights\n",
    "from layers import BilinearInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stn(input_shape=(32, 64, 1), sampling_size=(8, 16), num_classes=10):\n",
    "    image = Input(shape=input_shape)\n",
    "    #locnet = Conv2D(32, (5, 5), padding='same')(image)\n",
    "    locnet = CConv2D(32, (5, 5), padding='same')(image)\n",
    "\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    locnet = MaxPool2D(pool_size=(2, 2))(locnet)\n",
    "    #locnet = Conv2D(32, (5, 5), padding='same')(locnet)\n",
    "    locnet = CConv2D(32, (5, 5), padding='same')(locnet)\n",
    "\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    locnet = MaxPool2D(pool_size=(2, 2))(locnet)\n",
    "    #locnet = CConv2D(32, (5, 5), padding='same')(locnet)\n",
    "\n",
    "    #locnet = Conv2D(20, (5, 5), padding='same')(locnet)\n",
    "    #locnet = Activation('relu')(locnet)\n",
    "    #locnet = MaxPool2D(pool_size=(2, 2))(locnet)\n",
    "    locnet = Flatten()(locnet)\n",
    "    locnet = Dense(500)(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    locnet = Dense(200)(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    locnet = Dense(100)(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    locnet = Dense(50)(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    weights = get_initial_weights(50)\n",
    "    locnet = Dense(6, weights=weights)(locnet)\n",
    "    x = BilinearInterpolation(sampling_size)([image, locnet])\n",
    "    #x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = CConv2D(32, (5, 5), padding='same')(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D (size=(2,2))(x)\n",
    "    #x=  Conv2D(32, (3,3), padding='same')(x)\n",
    "    x = CConv2D(32, (5, 5), padding='same')(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D (size=(2,2))(x)\n",
    "    #x = Conv2D(32, (3,3), padding='same')(x)\n",
    "    #x = CConv2D(32, (5, 5), padding='same')(x)\n",
    "\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = Conv2D(32, (3,3), padding='same')(x)\n",
    "    #x = CConv2D(32, (5, 5), padding='same')(x)\n",
    "\n",
    "    #x = Activation('relu')(x)\n",
    "    #x = UpSampling2D (size=(2,2))(x)\n",
    "    #x = Conv2D(2, (3,3), padding='same')(x)\n",
    "    x = CConv2D(1, (5, 5), padding='same')(x)\n",
    "\n",
    "    x = Activation('linear')(x)\n",
    "    return Model(inputs=image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = stn()\n",
    "model.load_weights('best_weights_lead1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Start Data Assimilation Process #########################################\n",
    "model_vir=stn()\n",
    "model_vir.load_weights('best_weights_lead12.h5')\n",
    "time = 1200\n",
    "virtual_obs=np.zeros([100,32,64,1])\n",
    "dt=24\n",
    "dt_virtual=12\n",
    "\n",
    "count=0\n",
    "for t in range(0, time, dt_virtual):\n",
    "\n",
    "    if (t==0):\n",
    "        u = model_vir.predict(TRUTH[0,:].reshape([1,32,64,1]))\n",
    "    else:\n",
    "        u=model_vir.predict(u.reshape([1, 32, 64, 1]))\n",
    "\n",
    "    virtual_obs[count,:,:,0]=np.reshape(u,[32,64])\n",
    "    count=count+1\n",
    "\n",
    "vir_obs_rs=np.reshape(virtual_obs,[np.size(virtual_obs,0), np.size(virtual_obs,1)*np.size(virtual_obs,2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(32*64)\n",
    "P=np.eye(n,n)\n",
    "\n",
    "Q=0.03*np.eye(n,n)\n",
    "\n",
    "R=0.0001\n",
    "\n",
    "u_ensemble=np.zeros([32*64,2*32*64])\n",
    "\n",
    "pred=np.zeros([time,32,64,1])\n",
    "\n",
    "\n",
    "dt=24\n",
    "dt_virtual=12\n",
    "count=0\n",
    "for t in range(0, time, dt):\n",
    "        \n",
    "    for kk in range(0,dt-1):\n",
    "        if (kk==0):   \n",
    "          u=Z_rs[t+kk,:].reshape([1, 32, 64, 1 ])\n",
    "          u=model.predict(u.reshape([1,32,64,1]))\n",
    "         \n",
    "        \n",
    "        elif (kk == dt_virtual-1):\n",
    "\n",
    "            y = u\n",
    "            y, P =  ENKF(y, 2048, P, Q, R, vir_obs_rs[int((t+dt_virtual)/dt_virtual),:], model,u_ensemble)\n",
    "            u = y\n",
    "        else :\n",
    "      \n",
    "            u=model.predict(u.reshape([1, 32, 64, 1]))\n",
    "        \n",
    "        pred[count,:,:,0]=np.reshape(u,[32,64])\n",
    "        count=count+1\n",
    "    x = u   \n",
    "    x, P = ENKF(x, 2048, P, Q, R, Z_rs[t+dt,:], model,u_ensemble)\n",
    "   \n",
    "    print('output shape of ENKF', np.shape(x))\n",
    "    \n",
    "#    pred[count,:,:,0]=np.reshape(x,[32,64])\n",
    "#    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('DA_every24HR_lead1200_everytime_noise_' + str(noise)+ '_2DA.mat',dict([('prediction',pred),('truth',np.reshape(TRUTH,[np.size(Z_rs,0),32,64,1])),('noisy_obs',np.reshape(Z_rs,[np.size(Z_rs,0),32,64,1]))]))\n",
    "\n",
    "#sio.savemat('normalize_mean_std.mat',dict([('MEAN',M),('STD',sdev)]))\n",
    "print('Done writing file')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
